# Synthetic Video & Camera-Aware Trajectory Generator

Этот проект является форком оригинального репозитория [Poisson_blend](https://github.com/erkaman/Poisson_blend) и решает задачу генерации синтетических видео с динамической траекторией движения объекта, учитывающей движение камеры. Проект создан для того, чтобы обеспечить реалистичную вставку объекта в видео с учётом синтеза траектории, которая адаптируется к смещению камеры.

---

## Особенности проекта

- **Seamless Object Blending:** Использование алгоритма Poisson blending для естественной вставки объекта в целевые кадры.
- **Synthetic Trajectory Generation:** Генерация траектории объекта на основе ключевых кадров, заданных в текстовом файле.
- **Camera-Aware Trajectory Adjustment:** Корректировка сгенерированной траектории с учётом движения камеры.
- **Flexible Insertion Methods:** Поддержка двух методов вставки объекта – `poisson` (с Poisson blending) и `simple` (простая вставка).

---

## Структура проекта

```
.
├── build/                  # Директория для сборки C++ проекта
├── poisson_blend/          # Исходный код C++ оригинального Poisson_blend
├── simulate_trajectory.py  # Модуль для симуляции траектории
├── video_insert.py         # Модуль для обработки видео и вставки объекта
├── input.txt               # Пример файла с ключевыми кадрами (формат: frame_number x y [s])
├── vids/                   # Директория с видеофайлами для обработки
├── res/                    # Директория для сохранения результатов обработки видео
├── requirements.txt        # Файл с зависимостями для Python
└── README.md               # Этот файл
```

---

## Сборка C++ инструмента Poisson Blending

Проект использует библиотеки [lodepng](https://github.com/lvandeve/lodepng) и [Eigen](http://eigen.tuxfamily.org/) для работы с изображениями и матрицами. Обе библиотеки включены в репозиторий.

### Инструкции по сборке на Linux

Откройте терминал и выполните следующие команды:

```
mkdir build && cd build
```

После успешной сборки в каталоге `build` появится исполняемый файл `poisson_blend`.

### Пример использования

```
./poisson_blend -source path/to/source.png -target path/to/target.png -mask path/to/mask.png -output result.png -mx 280 -my 340
```

Параметры:
- **-source** — путь к исходному изображению (объекту).
- **-target** — путь к целевому изображению.
- **-mask** — путь к изображению маски, определяющему область вставки.
- **-output** — путь для сохранения результата.
- **-mx, -my** — координаты вставки объекта.

---

## Работа с Python модулями

Проект включает два основных Python скрипта, обеспечивающих генерацию синтетических видео с корректировкой траектории:

### 1. Симуляция траектории (`simulate_trajectory.py`)

Данный модуль генерирует траекторию объекта на основе ключевых кадров, заданных в текстовом файле.

#### Формат файла с ключевыми кадрами (`input.txt`)
Каждая строка файла должна иметь следующий формат:
```
frame_number x_coordinate y_coordinate [s_coordinate]
```
- **frame_number** — номер кадра.
- **x_coordinate, y_coordinate** — координаты вставки.
- **s_coordinate** — (опционально) коэффициент масштабирования (по умолчанию 1.0).

Пример:
```
0 100 200 1.0
10 150 250 1.2
20 200 300 1.0
```

---

### 2. Обработка видео и вставка объекта (`video_insert.py`)

Скрипт предназначен для обработки видеофайлов, расположенных в директории `vids/`. Он выполняет следующие этапы:
1. Извлечение кадров из видео.
2. Вычисление движения камеры.
3. Симуляция траектории с помощью модуля `simulate_trajectory.py`.
4. Вставка объекта в кадры видео с использованием выбранного метода:
   - **poisson** – с использованием Poisson blending.
   - **simple** – простая вставка.
5. Сборка итогового видео с заданным числом кадров в секунду.

---

## Использование скрипта

Ниже описан полный процесс подготовки и запуска скрипта для обработки видео и вставки объекта:

---

1. **Подготовка окружения:**
   - Убедитесь, что на вашем компьютере установлен Python (рекомендуется версия 3.6 или выше).
   - Склонируйте или скачайте репозиторий проекта и перейдите в его корневую директорию через терминал.

2. **Установка зависимостей:**
   - Все необходимые библиотеки перечислены в файле **`requirements.txt`**.
   - Выполните команду для установки зависимостей:
     ```
     pip install -r requirements.txt
     ```

3. **Подготовка файлов для обработки:**
   - **Видео:**  
     Поместите все видеофайлы, которые необходимо обработать, в директорию **`vids/`**. Поддерживаются форматы: `.mp4`, `.avi`, `.mov`, `.mkv`.
   - **Изображение объекта:**  
     Подготовьте изображение объекта (например, `object.png`), которое будет вставлено в кадры видео.
   - **Маска объекта:**  
     В зависимости от выбранного метода:
     - При использовании режима **`auto`** — подготовьте файл маски (например, `mask.png`) и укажите его путь при запуске.
     - При использовании режима **`grab`** — маска создаётся автоматически с помощью алгоритма GrabCut, и путь к файлу маски не требуется.

4. **Запуск скрипта:**
   - Откройте терминал в корневой директории проекта.
   - Примеры запуска:

     **a. С использованием Poisson blending (загрузка маски из файла):**
     ```
     python3 video_insert.py path/to/object.png path/to/mask.png --fps 15 --mask_method auto --insert_method poisson
     ```
     Здесь:
     - **path/to/object.png** — путь к изображению объекта.
     - **path/to/mask.png** — путь к файлу с маской (режим `auto`).
     - **--fps 15** — устанавливает частоту кадров итогового видео (15 fps).
     - **--mask_method auto** — указывает, что маска будет загружена из файла.
     - **--insert_method poisson** — выбирается метод вставки с использованием Poisson blending для естественного смешивания объекта с фоном.

     **b. С использованием автоматической генерации маски (GrabCut) и простой вставкой:**
     ```
     python3 video_insert.py path/to/object.png --fps 15 --mask_method grab --insert_method simple
     ```
     Здесь:
     - **path/to/object.png** — путь к изображению объекта.
     - При выборе режима **`grab`** аргумент для маски не указывается, так как маска генерируется автоматически.
     - **--mask_method grab** — устанавливает режим автоматической генерации маски.
     - **--insert_method simple** — выбирается простой метод вставки объекта.

5. **Процесс обработки:**
   - Скрипт проходит следующие этапы:
     - **Извлечение кадров:** Видео из папки **`vids/`** разбивается на кадры, которые сохраняются во временной директории (например, `save/raw_frames/`).
     - **Анализ движения камеры:** С использованием детектора (AKAZE) вычисляются смещения между кадрами.
     - **Симуляция траектории:** Модуль `simulate_trajectory.py` рассчитывает траекторию, по которой будет перемещаться объект, с учётом движения камеры.
     - **Вставка объекта:** Объект вставляется в каждый кадр с выбранным методом:
       - **Poisson blending:** Плавное смешивание объекта с фоном.
       - **Простая вставка:** Быстрая, но менее естественная интеграция.
     - **Сборка итогового видео:** Обработанные кадры объединяются в видео с указанной частотой кадров.

6. **Результаты:**
   - Итоговое видео сохраняется в директории **`res/`**. Имя файла формируется на основе названия исходного видео (например, `video_synced.mp4`).
   - Промежуточные файлы (например, извлечённые кадры) сохраняются в папке **`save/`**.
---

## Требования

### Для C++ части:
- CMake
- Компилятор C++ (gcc, clang и т.д.)

### Для Python скриптов:
- Python 3.x
- Зависимости, указанные в файле `requirements.txt` (например, numpy, scipy, opencv-python)

---

## Демонстрация работы
